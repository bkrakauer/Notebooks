{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "import helpers as h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Finding relations from public data (Google newsgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "\n",
    "unigram_model = gensim.models.KeyedVectors.load_word2vec_format\n",
    "('/Users/barak/Desktop/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll manually set up a collection of pairs of states/countries and their capitals. Then, we'll use these to establish the relation of \"is the capital of\" and test it on two examples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up a training set for \"is the capital of\" by hand\n",
    "\n",
    "capitals_train = [\n",
    "    (\"California\", \"Sacramento\"),\n",
    "    (\"Texas\", \"Austin\"),\n",
    "    (\"Canada\", \"Ottawa\"),\n",
    "    (\"France\", \"Paris\"),\n",
    "    (\"Russia\", \"Moscow\"),\n",
    "    (\"Massachusetts\", \"Boston\"),\n",
    "    (\"Italy\", \"Rome\"),\n",
    "    (\"India\", \"Delhi\"),\n",
    "    (\"China\", \"Beijing\"),\n",
    "    (\"Australia\", \"Canberra\"),\n",
    "    (\"England\", \"London\"),\n",
    "    (\"Peru\", \"Lima\"),\n",
    "    (\"Florida\", \"Tallahassee\"),\n",
    "    (\"Japan\", \"Tokyo\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This collects the difference of all state - capital vectors and averages them.\n",
    "\n",
    "diffs = [unigram_model[state] - unigram_model[city] for state, city in capitals_train]\n",
    "mean_diffs_vector = np.average(diffs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we know that we've discovered the \"is the capital of\" relationship? We can use it to find out what various capitals are!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Montpelier', 0.7260538339614868),\n",
       " (u'New_Hampshire', 0.674058198928833),\n",
       " (u'Brattleboro', 0.6718513369560242),\n",
       " (u'Maine', 0.6640110015869141),\n",
       " (u'Rutland', 0.6482397317886353),\n",
       " (u'St._Johnsbury', 0.6425949335098267),\n",
       " (u'Bennington', 0.6381337642669678),\n",
       " (u'Bellows_Falls', 0.6248161196708679),\n",
       " (u'UVM', 0.6161313056945801)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this take the difference of our test case (\"vermont\") and the vector that represents \"is the capital of\"\n",
    "\n",
    "transform = unigram_model[\"Vermont\"] - mean_diffs_vector\n",
    "results = unigram_model.similar_by_vector(transform)\n",
    "results[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be fair, it's not always the first hit, here, it's the second one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Portuguese', 0.6647554636001587),\n",
       " (u'Lisbon', 0.6610859632492065),\n",
       " (u'Porto', 0.6567690372467041),\n",
       " (u'Portugual', 0.6197739839553833),\n",
       " (u'Spain', 0.6073086261749268),\n",
       " (u'Madrid', 0.6043921709060669),\n",
       " (u'Benfica', 0.5990990400314331),\n",
       " (u'Oporto', 0.5915431976318359),\n",
       " (u'Barcelona', 0.5897266864776611)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = unigram_model[\"Portugal\"] - mean_diffs_vector\n",
    "results = unigram_model.similar_by_vector(transform)\n",
    "results[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try to discover the \"is a kind of relation\" in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_kind_of = [\n",
    "    (\"cat\", \"pet\"),\n",
    "    (\"doctor\", \"profession\"),\n",
    "    (\"sofa\", \"furniture\"),\n",
    "    (\"baseball\", \"sport\"),\n",
    "    (\"ford\", \"car\"),\n",
    "    (\"guitar\", \"instrument\"),\n",
    "    (\"dime\", \"coin\"),\n",
    "    (\"dog\", \"animal\"),\n",
    "    (\"mac\", \"computer\"),\n",
    "    (\"pasta\", \"food\"),\n",
    "    (\"bird\", \"animal\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kind_diffs = [unigram_model[thing] - unigram_model[type_] for thing, type_ in is_kind_of]\n",
    "k_diffs = np.average(kind_diffs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'reptile', 0.699384868144989),\n",
       " (u'lizards', 0.6936733722686768),\n",
       " (u'reptiles', 0.6410720348358154),\n",
       " (u'snake', 0.6338107585906982),\n",
       " (u'creature', 0.6250758171081543),\n",
       " (u'toad', 0.6105209589004517),\n",
       " (u'frog', 0.6086322665214539),\n",
       " (u'snakes', 0.5942181348800659),\n",
       " (u'mammal', 0.5934826135635376)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = unigram_model[\"lizard\"] - k_diffs\n",
    "results = unigram_model.similar_by_vector(transform)\n",
    "results[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, of course, the first hit is the right answer..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do this as a kid of entity recognition. For instance, here we're going to find out some more animals, given an initial seeding set of just 10 animals..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'cat', 0.7806287407875061),\n",
       " (u'bird', 0.7411798238754272),\n",
       " (u'rabbit', 0.7326385974884033),\n",
       " (u'dog', 0.7189368605613708),\n",
       " (u'critter', 0.6959779262542725),\n",
       " (u'animal', 0.6861838698387146),\n",
       " (u'turtle', 0.6853160262107849),\n",
       " (u'pup', 0.6818647980690002),\n",
       " (u'whale', 0.6802307367324829),\n",
       " (u'giraffe', 0.6801244020462036),\n",
       " (u'otter', 0.675615131855011),\n",
       " (u'squirrel', 0.6697624921798706),\n",
       " (u'mammal', 0.6691585779190063),\n",
       " (u'cats', 0.668297290802002),\n",
       " (u'fox', 0.6656603217124939),\n",
       " (u'reptile', 0.663225531578064),\n",
       " (u'dolphin', 0.6631218194961548),\n",
       " (u'animals', 0.6623847484588623),\n",
       " (u'frog', 0.6570603847503662),\n",
       " (u'lizard', 0.6523070335388184)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# animals\n",
    "animals = [\n",
    "    'dog',\n",
    "    'cat',\n",
    "    'lion',\n",
    "    'giraffe',\n",
    "    'horse',\n",
    "    'duck',\n",
    "    'bird',\n",
    "    'fish',\n",
    "    'whale',\n",
    "    'mouse'\n",
    "]\n",
    "animal_vecs = [unigram_model[animal] for animal in animals]\n",
    "avg_animals = np.average(animal_vecs, axis=0)\n",
    "results = unigram_model.similar_by_vector(avg_animals, topn=20)\n",
    "results = [res for res in results if res not in animals]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Cisco Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can move on to a business use case. Cisco wants to understand a collection of manuals about their ASA firewalls. We'll look to see if we can build out the relationship of \"support\" for various security protocols..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we're just loading the data and preparing our bigram detector..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = [\"title\", \"id\", \"tech_solution\", \"protocol\", \"concept\", \"body\"]\n",
    "df = h.parse_jsons(\"/Users/barak/projects/cisco/data/\", cols)\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "phrases = gensim.models.phrases.Phrases(h.processtxt(df.body), min_count=2000, threshold=2)\n",
    "bigram_detector = gensim.models.phrases.Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# builds the bigram model\n",
    "\n",
    "bigram_model = gensim.models.Word2Vec(bigram_detector[h.processtxt(df.body)], min_count=30, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to pull a list of security protocols from our dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ipsec', u'ike', u'ikev2', u'ikev1', u'ssl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "protocols = h.get_protocols(df.protocol)\n",
    "protocols = [protocol.lower() for protocol in protocols]\n",
    "\n",
    "# determine the vector for protocols.\n",
    "\n",
    "protocol_vecs = [bigram_model[protocol] for protocol in protocols]\n",
    "mean_protocols = np.average(protocol_vecs, axis = 0)\n",
    "protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# give it a list of products\n",
    "\n",
    "products = [\"asa5540\", \"asa5505\", \"asa5510\", \"asa5520\", \"asa5500\", \"asa_5505\"]\n",
    "product_vecs = [bigram_model[prod] for prod in products]\n",
    "mean_products = np.average(product_vecs, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the \"product to protocol\" vector\n",
    "prod_to_protocol = mean_products - mean_protocols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what we're going to do is see how closely the \"supports\" relation holds for each of the possible protocols for some of our products...\n",
    "\n",
    "What's cool about this is that the ASA 5540 supports IKEv1 but not v2, and that the ASA 5505 supports IKEv2 but not v1. The model shows us that this holds, just looking at the similarity score for these protocols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'ike', 0.315812349319458),\n",
       " (u'ikev1', 0.30333074927330017),\n",
       " (u'ipsec', 0.26640862226486206),\n",
       " (u'ssl', 0.24321871995925903),\n",
       " (u'ikev2', 0.16395549476146698)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = bigram_model['asa5540'] - prod_to_protocol\n",
    "results = bigram_model.similar_by_vector(diff, topn=10000)\n",
    "prot_results = [result for result in results if result[0] in protocols]\n",
    "prot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'ikev2', 0.303021103143692),\n",
       " (u'ike', 0.2829524278640747),\n",
       " (u'ssl', 0.27673107385635376),\n",
       " (u'ikev1', 0.16295677423477173),\n",
       " (u'ipsec', 0.1360032707452774)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = bigram_model['asa5505'] - prod_to_protocol\n",
    "results = bigram_model.similar_by_vector(diff, topn=10000)\n",
    "prot_results = [result for result in results if result[0] in protocols]\n",
    "prot_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
